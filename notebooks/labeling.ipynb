{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0f4761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.36.0\n",
      "  Downloading transformers-4.36.0-py3-none-any.whl.metadata (126 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from transformers==4.36.0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from transformers==4.36.0) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from transformers==4.36.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from transformers==4.36.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from transformers==4.36.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from transformers==4.36.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from transformers==4.36.0) (2.32.3)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.0)\n",
      "  Downloading tokenizers-0.15.2-cp310-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from transformers==4.36.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from transformers==4.36.0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers==4.36.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from requests->transformers==4.36.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from requests->transformers==4.36.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from requests->transformers==4.36.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from requests->transformers==4.36.0) (2025.1.31)\n",
      "Downloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\n",
      "   ---------------------------------------- 0.0/8.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.2 MB 3.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.3/8.2 MB 3.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.4/8.2 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.1/8.2 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.2/8.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.0/8.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.0/8.2 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.8/8.2 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.2/8.2 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp310-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 4.8 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, transformers\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.36.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.1-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "  Downloading torchaudio-2.9.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "  Downloading torchaudio-2.8.0-cp310-cp310-win_amd64.whl.metadata (7.2 kB)\n",
      "  Downloading torchaudio-2.7.0-cp310-cp310-win_amd64.whl.metadata (6.7 kB)\n",
      "  Downloading torchaudio-2.6.0-cp310-cp310-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.6.0-cp310-cp310-win_amd64.whl (204.2 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading torchaudio-2.6.0-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.8/2.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.8/2.4 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, torch, torchaudio\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.7.1\n",
      "    Uninstalling torch-2.7.1:\n",
      "      Successfully uninstalled torch-2.7.1\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.7.1\n",
      "    Uninstalling torchaudio-2.7.1:\n",
      "      Successfully uninstalled torchaudio-2.7.1\n",
      "Successfully installed sympy-1.13.1 torch-2.6.0 torchaudio-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ASUS\\anaconda3\\envs\\spacy-env\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from datasets) (0.33.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\envs\\spacy-env\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers==4.36.0\n",
    "%pip install torch torchvision torchaudio\n",
    "%pip install pandas numpy scikit-learn matplotlib seaborn tqdm datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3216a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\spacy-env\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\spacy-env\\lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d451ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea00a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Project-Information-Retrieval\\notebooks\n",
      "\n",
      "Files in data/raw:\n",
      "  Folder data/raw not found!\n",
      "Loaded ../data/raw/Gojek_Reviews_2021.csv: 69485 reviews\n",
      "Loaded ../data/raw/Gojek_Reviews_2022.csv: 161736 reviews\n",
      "Loaded ../data/raw/Gojek_Reviews_2023.csv: 81725 reviews\n",
      "Loaded ../data/raw/Gojek_Reviews_2024.csv: 76319 reviews\n",
      "Loaded ../data/raw/Gojek_Reviews_2025.csv: 47235 reviews\n",
      "\n",
      "Successfully loaded 5 files\n",
      "Total reviews: 436500\n",
      "Columns: ['content', 'score', 'at']\n",
      "\n",
      "First 5 rows:\n",
      "                                             content  score  \\\n",
      "0                                               Baik      5   \n",
      "1                                             Mantap      4   \n",
      "2                                    Sangat membantu      5   \n",
      "3  My problem have been solved.. thanks.. It shou...      5   \n",
      "4                                                Top      5   \n",
      "\n",
      "                    at  \n",
      "0  2021-12-31 23:49:14  \n",
      "1  2021-12-31 23:40:15  \n",
      "2  2021-12-31 23:22:29  \n",
      "3  2021-12-31 23:21:57  \n",
      "4  2021-12-31 23:19:09  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "print(\"\\nFiles in data/raw:\")\n",
    "try:\n",
    "    files_in_raw = os.listdir('data/raw')\n",
    "    for f in files_in_raw:\n",
    "        print(f\"  - {f}\")\n",
    "except:\n",
    "    print(\"  Folder data/raw not found!\")\n",
    "\n",
    "files = [\n",
    "    '../data/raw/Gojek_Reviews_2021.csv',\n",
    "    '../data/raw/Gojek_Reviews_2022.csv',\n",
    "    '../data/raw/Gojek_Reviews_2023.csv',\n",
    "    '../data/raw/Gojek_Reviews_2024.csv',\n",
    "    '../data/raw/Gojek_Reviews_2025.csv'\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    try:\n",
    "        try:\n",
    "            df_temp = pd.read_csv(file)\n",
    "        except UnicodeDecodeError:\n",
    "            df_temp = pd.read_csv(file, encoding='latin-1')\n",
    "        except:\n",
    "            df_temp = pd.read_csv(file, encoding='ISO-8859-1')\n",
    "        \n",
    "        dfs.append(df_temp)\n",
    "        print(f\"Loaded {file}: {len(df_temp)} reviews\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file}: {e}\")\n",
    "\n",
    "if len(dfs) == 0:\n",
    "    print(\"\\nNo CSV files loaded! Please check your file paths.\")\n",
    "    print(\"\\nTips:\")\n",
    "    print(\"1. Make sure you're running the notebook from the correct directory\")\n",
    "    print(\"2. Or use absolute path (full path) to your CSV files\")\n",
    "else:\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"\\nSuccessfully loaded {len(dfs)} files\")\n",
    "    print(f\"Total reviews: {len(df)}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01443d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "378c6fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning: 436494 reviews\n"
     ]
    }
   ],
   "source": [
    "text_column = 'content'\n",
    "score_column = 'score'\n",
    "\n",
    "df['cleaned_text'] = df[text_column].apply(clean_text)\n",
    "df = df[df['cleaned_text'].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "print(f\"Data after cleaning: {len(df)} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701733a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_to_sentiment(rating):\n",
    "    if pd.isna(rating):\n",
    "        return None\n",
    "    rating = int(rating)\n",
    "    if rating <= 2:\n",
    "        return 0   \n",
    "    elif rating == 3:\n",
    "        return 1   \n",
    "    else:\n",
    "        return 2   \n",
    "\n",
    "df['label'] = df[score_column].apply(rating_to_sentiment)\n",
    "df = df.dropna(subset=['label']).reset_index(drop=True)\n",
    "df['label'] = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b04750a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Distribution:\n",
      "Negatif: 109989 (25.20%)\n",
      "Netral: 17397 (3.99%)\n",
      "Positif: 309108 (70.82%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nLabel Distribution:\")\n",
    "for label, count in df['label'].value_counts().sort_index().items():\n",
    "    sentiment = ['Negatif', 'Netral', 'Positif'][label]\n",
    "    print(f\"{sentiment}: {count} ({count/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='label')\n",
    "plt.xticks([0, 1, 2], ['Negatif', 'Netral', 'Positif'])\n",
    "plt.title('Distribution of Sentiment Labels')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7de6ed0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 349195 samples\n",
      "Validation: 43649 samples\n",
      "Test: 43650 samples\n"
     ]
    }
   ],
   "source": [
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df['cleaned_text'].tolist(),\n",
    "    df['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['label']\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts,\n",
    "    temp_labels,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(train_texts)} samples\")\n",
    "print(f\"Validation: {len(val_texts)} samples\")\n",
    "print(f\"Test: {len(test_texts)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dee85d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Using CPU (training will be slower)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Using CPU (training will be slower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4e3cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying model: indolem/indobert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Using model: indolem/indobert-base-uncased\n",
      "\n",
      "Model loaded on cpu\n"
     ]
    }
   ],
   "source": [
    "model_options = [\n",
    "    \"indolem/indobert-base-uncased\",\n",
    "    \"cahya/bert-base-indonesian-1.5G\",\n",
    "    \"indobenchmark/indobert-base-p2\"\n",
    "]\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "\n",
    "for model_name in model_options:\n",
    "    try:\n",
    "        print(f\"\\nTrying model: {model_name}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=3,\n",
    "            id2label={0: \"Negatif\", 1: \"Netral\", 2: \"Positif\"},\n",
    "            label2id={\"Negatif\": 0, \"Netral\": 1, \"Positif\": 2}\n",
    "        )\n",
    "        \n",
    "        model.to(device)\n",
    "        print(f\"Success! Using model: {model_name}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {e}\")\n",
    "        continue\n",
    "\n",
    "if model is None:\n",
    "    print(\"\\nAll models failed to load!\")\n",
    "else:\n",
    "    print(f\"\\nModel loaded on {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "803e8e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9e99c1c93848ccb4c58e7174928c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/349195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bfcab59f404472a7395b2ad9bce52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43649 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d15a7e2edc2455b8f29a86fec2ffe25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43650 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_dict({'text': train_texts, 'label': train_labels})\n",
    "val_dataset = Dataset.from_dict({'text': val_texts, 'label': val_labels})\n",
    "test_dataset = Dataset.from_dict({'text': test_texts, 'label': test_labels})\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "print(\"Tokenizing datasets...\")\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "print(\"Tokenization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155bdd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: 436494 reviews\n",
      "Sampled data: 87298 reviews (20.0%)\n",
      "\n",
      "Label Distribution (Sampled):\n",
      "Negatif: 21848 (25.03%)\n",
      "Netral: 3475 (3.98%)\n",
      "Positif: 61975 (70.99%)\n",
      "\n",
      "New split:\n",
      "Train: 69838 samples\n",
      "Validation: 8730 samples\n",
      "Test: 8730 samples\n",
      "\n",
      "Tokenizing sampled datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2338726778764d56a18b78c7748a71c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/69838 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf8c25359c745378261baa08fa5871b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8730 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac73cfa63ae4dc7a795769b9de83bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8730 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n",
      "\n",
      "Device: cpu\n",
      "Epochs: 2\n",
      "Batch size: 16\n",
      "Training batches per epoch: 4365\n",
      "Validation batches: 273\n",
      "\n",
      "Estimated training time: 3.6 hours (214 minutes)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch 1/2\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 4365/4365 [2:21:29<00:00,  1.94s/it, loss=0.3835, avg_loss=0.3264]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Training Loss: 0.3264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 273/273 [05:13<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Loss: 0.3045\n",
      "Validation Accuracy: 0.9021\n",
      "Epoch Time: 146.7 minutes\n",
      "New best validation accuracy. Saving model...\n",
      "\n",
      "================================================================================\n",
      "Epoch 2/2\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 4365/4365 [2:23:14<00:00,  1.97s/it, loss=0.6293, avg_loss=0.2891]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Training Loss: 0.2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 273/273 [04:52<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Loss: 0.2964\n",
      "Validation Accuracy: 0.9027\n",
      "Epoch Time: 148.1 minutes\n",
      "New best validation accuracy. Saving model...\n",
      "\n",
      "================================================================================\n",
      "Training Complete\n",
      "Best Validation Accuracy: 0.9027\n",
      "Model saved to: ./models/gojek_sentiment_model\n"
     ]
    }
   ],
   "source": [
    " \n",
    "sample_percentage = 0.2\n",
    "sample_size = int(len(df) * sample_percentage)\n",
    "\n",
    "df_sampled = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(f\"Original data: {len(df)} reviews\")\n",
    "print(f\"Sampled data: {len(df_sampled)} reviews ({sample_percentage*100}%)\")\n",
    "\n",
    "# Create labels untuk sampled data\n",
    "def rating_to_sentiment(rating):\n",
    "    if pd.isna(rating):\n",
    "        return None\n",
    "    rating = int(rating)\n",
    "    if rating <= 2:\n",
    "        return 0\n",
    "    elif rating == 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df_sampled['label'] = df_sampled[score_column].apply(rating_to_sentiment)\n",
    "df_sampled = df_sampled.dropna(subset=['label']).reset_index(drop=True)\n",
    "df_sampled['label'] = df_sampled['label'].astype(int)\n",
    "\n",
    "print(\"\\nLabel Distribution (Sampled):\")\n",
    "for label, count in df_sampled['label'].value_counts().sort_index().items():\n",
    "    sentiment = ['Negatif', 'Netral', 'Positif'][label]\n",
    "    print(f\"{sentiment}: {count} ({count/len(df_sampled)*100:.2f}%)\")\n",
    " \n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df_sampled['cleaned_text'].tolist(),\n",
    "    df_sampled['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_sampled['label']\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts,\n",
    "    temp_labels,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(f\"\\nNew split:\")\n",
    "print(f\"Train: {len(train_texts)} samples\")\n",
    "print(f\"Validation: {len(val_texts)} samples\")\n",
    "print(f\"Test: {len(test_texts)} samples\")\n",
    " \n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict({'text': train_texts, 'label': train_labels})\n",
    "val_dataset = Dataset.from_dict({'text': val_texts, 'label': val_labels})\n",
    "test_dataset = Dataset.from_dict({'text': test_texts, 'label': test_labels})\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "print(\"\\nTokenizing sampled datasets...\")\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "print(\"Tokenization complete\")\n",
    " \n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    shuffle=True, \n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "num_epochs = 2\n",
    "gradient_accumulation_steps = 2\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(f\"\\nDevice: {device}\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Batch size: {train_dataloader.batch_size}\")\n",
    "print(f\"Training batches per epoch: {len(train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(val_dataloader)}\")\n",
    "\n",
    "# Estimasi waktu\n",
    "estimated_seconds = len(train_dataloader) * 1.47 * num_epochs\n",
    "estimated_hours = estimated_seconds / 3600\n",
    "print(f\"\\nEstimated training time: {estimated_hours:.1f} hours ({estimated_hours*60:.0f} minutes)\\n\")\n",
    "\n",
    "training_history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_dataloader, desc=\"Training\")\n",
    "    \n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss / gradient_accumulation_steps\n",
    "        total_loss += loss.item() * gradient_accumulation_steps\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item() * gradient_accumulation_steps:.4f}',\n",
    "            'avg_loss': f'{total_loss/(step+1):.4f}'\n",
    "        })\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    training_history['train_loss'].append(avg_train_loss)\n",
    "    \n",
    "    print(f\"\\nAverage Training Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels_list = []\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            total_val_loss += outputs.loss.item()\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            val_preds.extend(predictions.cpu().numpy())\n",
    "            val_labels_list.extend(batch['labels'].cpu().numpy())\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_accuracy = accuracy_score(val_labels_list, val_preds)\n",
    "    \n",
    "    training_history['val_loss'].append(avg_val_loss)\n",
    "    training_history['val_acc'].append(val_accuracy)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Epoch Time: {epoch_time/60:.1f} minutes\")\n",
    "    \n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        print(\"New best validation accuracy. Saving model...\")\n",
    "        output_dir = './models/gojek_sentiment_model_best'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        model.save_pretrained(output_dir)\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Training Complete\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "output_dir = './models/gojek_sentiment_model'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49cf001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|| 13641/13641 [2:23:09<00:00,  1.59it/s]  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 63\u001b[0m\n\u001b[0;32m     52\u001b[0m     output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/gojek_reviews_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     53\u001b[0m     df_sentiment\u001b[38;5;241m.\u001b[39mto_csv(output_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     55\u001b[0m summary_stats \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Reviews\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(df),\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]),\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeutral\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m]),\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegative \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeutral \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositive \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtest_accuracy\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Confidence\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction_confidence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m }\n\u001b[0;32m     67\u001b[0m summary_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([summary_stats])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     68\u001b[0m summary_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "def batch_predict(texts, model, tokenizer, device, batch_size=32):\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        cleaned_texts = [clean_text(text) for text in batch_texts]\n",
    "        \n",
    "        inputs = tokenizer(cleaned_texts, return_tensors='pt', \n",
    "                          truncation=True, max_length=128, padding=True)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            predicted_classes = torch.argmax(probs, dim=-1)\n",
    "            confidences = torch.max(probs, dim=-1).values\n",
    "        \n",
    "        for pred, conf in zip(predicted_classes.cpu().numpy(), confidences.cpu().numpy()):\n",
    "            predictions.append({\n",
    "                'predicted_label': int(pred),\n",
    "                'confidence': float(conf)\n",
    "            })\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "all_predictions = batch_predict(df['cleaned_text'].tolist(), model, tokenizer, device, batch_size=32)\n",
    "\n",
    "df['predicted_label'] = [p['predicted_label'] for p in all_predictions]\n",
    "df['prediction_confidence'] = [p['confidence'] for p in all_predictions]\n",
    "df['predicted_sentiment'] = df['predicted_label'].map({\n",
    "    0: 'Negatif', 1: 'Netral', 2: 'Positif'\n",
    "})\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "output_folder = 'sentiment_results'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "output_file_all = f'{output_folder}/gojek_reviews_labeled_{timestamp}.csv'\n",
    "df.to_csv(output_file_all, index=False, encoding='utf-8-sig')\n",
    "\n",
    "high_conf = df[df['prediction_confidence'] > 0.8]\n",
    "output_file_high = f'{output_folder}/gojek_reviews_high_confidence_{timestamp}.csv'\n",
    "high_conf.to_csv(output_file_high, index=False, encoding='utf-8-sig')\n",
    "\n",
    "for sentiment_label, sentiment_name in [(0, 'negative'), (1, 'neutral'), (2, 'positive')]:\n",
    "    df_sentiment = df[df['predicted_label'] == sentiment_label]\n",
    "    output_file = f'{output_folder}/gojek_reviews_{sentiment_name}_{timestamp}.csv'\n",
    "    df_sentiment.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "summary_stats = {\n",
    "    'Total Reviews': len(df),\n",
    "    'Negative': len(df[df['predicted_label'] == 0]),\n",
    "    'Neutral': len(df[df['predicted_label'] == 1]),\n",
    "    'Positive': len(df[df['predicted_label'] == 2]),\n",
    "    'Negative %': f\"{len(df[df['predicted_label'] == 0])/len(df)*100:.2f}%\",\n",
    "    'Neutral %': f\"{len(df[df['predicted_label'] == 1])/len(df)*100:.2f}%\",\n",
    "    'Positive %': f\"{len(df[df['predicted_label'] == 2])/len(df)*100:.2f}%\",\n",
    "    'Test Accuracy': f\"{test_accuracy:.4f}\",\n",
    "    'Avg Confidence': f\"{df['prediction_confidence'].mean():.2%}\"\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary_stats]).T\n",
    "summary_df.columns = ['Value']\n",
    "summary_file = f'{output_folder}/summary_{timestamp}.csv'\n",
    "summary_df.to_csv(summary_file, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Done. Results saved in: {output_folder}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
